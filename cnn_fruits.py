# -*- coding: utf-8 -*-
"""CNN_fruits.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fRXqNjRUutP1Ao9pJc7uVjMpUzyxksEA

# Grayscale doodle image classification using Convolution Neural Network (CNN)
"""

import time
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

import tensorflow as tf
from tensorflow.keras import datasets, layers, models

from sklearn.metrics import classification_report

data_dir = "/content/drive/MyDrive/Data/train"
data2_dir = "/content/drive/MyDrive/Data/train2"
test1_dir = "/content/drive/MyDrive/Data/test1"
test2_dir = "/content/drive/MyDrive/Data/test2"

from google.colab import drive
drive.mount('/content/drive')

def plot_confusion_matrix(y_true, y_pred, classes,
                          normalize=False,
                          title=None,
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    from sklearn.metrics import confusion_matrix

    if not title:
        if normalize:
            title = 'Normalized confusion matrix'
        else:
            title = 'Confusion matrix, without normalization'

    # Compute confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    # Only use the labels that appear in the data
    # classes = classes[unique_labels(y_true, y_pred)]
    # if normalize:
    #     cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    #     print("Normalized confusion matrix")
    # else:
    #     print('Confusion matrix, without normalization')

    fig, ax = plt.subplots()
    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)
    ax.figure.colorbar(im, ax=ax)
    # We want to show all ticks...
    ax.set(xticks=np.arange(cm.shape[1]),
           yticks=np.arange(cm.shape[0]),
           # ... and label them with the respective list entries
           xticklabels=classes, yticklabels=classes,
           title=title,
           ylabel='True label',
           xlabel='Predicted label')

    # Rotate the tick labels and set their alignment.
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right",
             rotation_mode="anchor")

    # Loop over data dimensions and create text annotations.
    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, format(cm[i, j], fmt),
                    ha="center", va="center",
                    color="white" if cm[i, j] > thresh else "black")
    fig.tight_layout()
    return ax

"""## Loading images"""

batch_size = 1
img_height = 224
img_width = 224

train_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data2_dir,
  validation_split=0.2,
  subset="training",
  seed=0,
  image_size=(img_height, img_width),
  batch_size=batch_size,
  color_mode='grayscale'
)

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data2_dir,
  validation_split=0.2,
  subset="validation",
  seed=0,
  image_size=(img_height, img_width),
  batch_size=batch_size,
  color_mode='grayscale'
)

# SHOULD HAVE 800 FILES
class_names = train_ds.class_names
print("Classes: ", end='')
print(class_names)

AUTOTUNE = tf.data.experimental.AUTOTUNE

def configure_for_performance(ds, shuffle=True):
  ds = ds.cache()
  if shuffle:
    ds = ds.shuffle(buffer_size=1000)
  ds = ds.prefetch(buffer_size=AUTOTUNE)
  return ds

train_ds = configure_for_performance(train_ds)
val_ds = configure_for_performance(val_ds)

"""## Building the model"""

model = models.Sequential()
model.add(layers.Input(shape=(224, 224, 1)))
model.add(layers.experimental.preprocessing.Rescaling(1./255))
model.add(layers.Conv2D(32, (5, 5), strides=(2, 2), activation='relu', padding='same'))
model.add(layers.Conv2D(32, (3, 3), strides=(2, 2), activation='relu', padding='same'))
model.add(layers.MaxPooling2D((3, 3)))
model.add(layers.Dropout(0.2))
model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))
model.add(layers.MaxPooling2D((3, 3)))
model.add(layers.Dropout(0.2))
model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))
model.add(layers.MaxPooling2D((3, 3)))


model.add(layers.Flatten())
model.add(layers.Dense(10, activation='relu'))
model.add(layers.Dense(len(class_names), activation='softmax'))

model.summary()

"""## Fitting the model"""

# lower training rate by one magnitude
adam = tf.keras.optimizers.Adam(
    learning_rate=0.0001 #0.00001 is too small and 0.001 is too big
    #0.0001 is good
)

model.compile(
  optimizer=adam,
  loss='SparseCategoricalCrossentropy',
  metrics=['accuracy']
)

start = time.perf_counter()
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=10,
  verbose=2,
)

print("Time elapsed: ", end='')
print("{:.1f}".format(time.perf_counter() - start))

"""## Plotting changes of model accuracy & loss during training"""

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

ax1.plot(history.history['accuracy'])
ax1.plot(history.history['val_accuracy'])
ax1.set_title('model accuracy')
ax1.set_ylabel('accuracy')
ax1.set_xlabel('epoch')
ax1.legend(['train', 'test'], loc='upper left')

# summarize history for loss
ax2.plot(history.history['loss'])
ax2.plot(history.history['val_loss'])
ax2.set_title('model loss')
ax2.set_ylabel('loss')
ax2.set_xlabel('epoch')
ax2.legend(['train', 'test'], loc='upper right')

fig.show()

"""## Presenting result"""

y_pred = []
y_true = []
for image, label in val_ds.take(-1):
  pred = np.argmax(model.predict(image), axis=1)[0] # argmax because softmax outputs probabilities
  y_pred.append(pred) 
  label = label.numpy()[0]
  y_true.append(label)

print(y_true)
print(y_pred)

plot_confusion_matrix(y_true, y_pred, classes=class_names)
print(classification_report(y_true, y_pred, target_names=class_names))

for image, label in val_ds.take(3):
  fig, (bar, img) = plt.subplots(1, 2, figsize=(10, 5))
  pred = model.predict(image)[0]
  bar.bar(class_names, pred)
  bar.set_title("Prediction")
  img.imshow(image[0].numpy().squeeze(axis=2), cmap='gray')
  img.axis("off")
  img.set_title("Image")
  fig.show()

data_augmentation = tf.keras.Sequential([
  layers.Input(shape=(224, 224, 3)),
  layers.experimental.preprocessing.RandomFlip("horizontal"),
  # layers.experimental.preprocessing.RandomRotation(0.2),
])

for img, label in train_ds.take(1):
  img = tf.expand_dims(img, 0)
  plt.figure(figsize=(10, 10))
  for i in range(9):
    print(image.shape)
    augmented_image = data_augmentation(image)
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(augmented_image[0].numpy().squeeze(axis=2), cmap='gray')
    plt.axis("off")

from keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest')